{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "# from embedding_utils import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def get_embeddings(sentences, model_name=\"paraphrase-MiniLM-L6-v2\"):\n",
    "    \"\"\" Returns embeddings for a provided list of text samples\n",
    "\n",
    "    Args:\n",
    "        sentences: List-like set of text samples to be embedded\n",
    "        model_name: embedding model to use (paraphrase-MiniLM-L6-v2 is Sentence-BERT)\n",
    "\n",
    "    Returns:\n",
    "        sentence embeddings: array of embedding vectors, order corresponds to order of input sentences\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    return(sentence_embeddings)\n",
    "\n",
    "\n",
    "def get_transform(data, method, n_neighbors=15, min_dist=0.1, n_pca=50, n_umap=2, metric='euclidean'):\n",
    "    \"\"\" Implements transformation of high-dimensional data using UMAP and PCA, either seperately or in tandem. \n",
    "\n",
    "    Args:\n",
    "        data (Series): Set of vectors to be transformed. \n",
    "        method (String - 'umap', 'pca', or 'both'): Defines which transformation methods to use. If both, function will first run PCA, then run UMAP on the results of the PCA transform.\n",
    "        n_neighbors (int, optional): Parameter for UMAP. Defaults to 15.\n",
    "        min_dist (float, optional): Parameter for UMAP. Defaults to 0.1.\n",
    "        n_pca (int, optional): Dimensionality of vectors to be returned from PCA transform. Defaults to 50.\n",
    "        n_umap (int, optional): Dimensionality of vectors to be returned from UMAP transform. Defaults to 2.\n",
    "        metric (str, optional): Distance metric for UMAP. Defaults to 'euclidean'.\n",
    "\n",
    "    Returns:\n",
    "        tfm: array of transformed vectors \n",
    "    \"\"\"\n",
    "    if method == 'umap':\n",
    "        fit = umap.UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            n_components=n_umap,\n",
    "            metric=metric\n",
    "        )\n",
    "        tfm = fit.fit_transform(data);\n",
    "    if method == 'pca':\n",
    "        n_pca=n_pca\n",
    "        fit = PCA(\n",
    "            n_components=n_pca\n",
    "        )\n",
    "        tfm = fit.fit_transform(data)\n",
    "    if method == 'both':\n",
    "        pca = PCA(n_components=n_pca).fit_transform(data)\n",
    "        tfm = umap.UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            n_components=n_umap,\n",
    "            metric=metric\n",
    "        ).fit_transform(pca)\n",
    "        \n",
    "    return tfm\n",
    "\n",
    "\n",
    "def sil_range(tfm, test_vals=np.arange(5,20)):\n",
    "    \"\"\"\n",
    "    Iteratively tests k-means clustering over a range of k values with silhouette scores to identify an optimal k value. Tested k-values are displayed in a plot\n",
    "\n",
    "    Args:\n",
    "        tfm: array of transformed values, such as those output by get_transform\n",
    "        test_vals: List of integer k-values to test. Default to test all values between 5 and 20\n",
    "\n",
    "    Returns:\n",
    "        (int, float): optimal k-value and associated silhouette score\n",
    "    \"\"\"\n",
    "    print(\"Testing k values:\")\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in test_vals:\n",
    "        print(k)\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0).fit(tfm)\n",
    "        silhouette_scores.append(silhouette_score(tfm, kmeans.labels_))\n",
    "\n",
    "    df = pd.DataFrame({'k':test_vals, 'silhouette':silhouette_scores})\n",
    "    fig = px.bar(df, x='k', y='silhouette')\n",
    "    fig.show()\n",
    "    \n",
    "    return int(df.loc[df['silhouette'].argmax()]['k']), df.loc[df['silhouette'].argmax()]['silhouette']\n",
    "\n",
    "\n",
    "def px_plot(data, save=False, fpath=\"fig.html\", title=\"Semantic Clustering of Monkeypox Discussion on Twitter\", colormap=False):\n",
    "    \"\"\"\n",
    "    Function for generating interactive plot of transformed tweet embeddings. Includes displaying various additional parameters as hover data. Depending on your data format, you may need to modify this to correspond to your tweet metadata and variable names.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame of tweets and embedding coordinates. For this function, should contain column labeled as:\n",
    "            x: transformed x-coordinate\n",
    "            y: transformed y-coordinate\n",
    "            hover_text: text to be displayed when hovering on plot\n",
    "            retweet_count, favorite_count: Tweet metadata\n",
    "            k_means_category\n",
    "            size: desired size of points on plot. For twitter data, something like ln(retweets) can be useful\n",
    "        save: Set to True to save your plot as .html file\n",
    "        fpath: filepath and name to save your plot .html\n",
    "        title: set title of plot\n",
    "        colormap: Dict of label:color pairs for coloring points (e.g. kmeans category:color)\n",
    "    \"\"\"\n",
    "    pyo.init_notebook_mode()\n",
    "\n",
    "    if not colormap:\n",
    "        fig = px.scatter(\n",
    "            data,\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            hover_data=[\"hover_text\", 'retweet_count', 'favorite_count', \"k_means_category\"],\n",
    "            size=\"size\",\n",
    "            title=title,\n",
    "        )\n",
    "    else:\n",
    "        fig = px.scatter(\n",
    "            data,\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            color=\"label\",\n",
    "            hover_data=[\"hover_text\", 'retweet_count', 'favorite_count', \"k_means_category\"],\n",
    "            size=\"size\",\n",
    "            title=title,\n",
    "            color_discrete_map=colormap,\n",
    "        )\n",
    "\n",
    "\n",
    "    fig.layout.showlegend = False\n",
    "\n",
    "    fig.update_traces(\n",
    "        customdata=sampled[['hover_text', 'favorite_count', 'retweet_count', 'k_means_category', 'id']], \n",
    "        hovertemplate='%{customdata[0]}<br><br>'\n",
    "            +'Likes: %{customdata[1]}   Retweets: %{customdata[2]}<br>'\n",
    "            +'K-Means Category: %{customdata[3]}<br>'\n",
    "            +'TweetID: %{customdata[4]}',\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1600,\n",
    "        height=900,\n",
    "    )\n",
    "\n",
    "#     fig.update(layout_coloraxis_showscale=False)\n",
    "    fig.update_yaxes(title='y', visible=False)\n",
    "    fig.update_xaxes(title='x', visible=False)\n",
    "    fig.update(layout_showlegend=True)\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"right\",\n",
    "        x=0.99,),\n",
    "        legend_title_text='Topic Label'\n",
    "    )\n",
    "    \n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    if save:\n",
    "        print(\"Saving figure as: \", fpath)\n",
    "        fig.write_html(fpath)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map kmeans cluster #'s to cluster labels\n",
    "cluster_names = {\n",
    "    0:'Noise - Outside', \n",
    "    1:'Noise - Middle', \n",
    "    2:'Case reports', \n",
    "    3:'Transmissibility, MSM communities', \n",
    "    4:'WHO Emergency', \n",
    "    5:'Vaccines', \n",
    "    6:'Monkeypox vs. Covid'\n",
    "}\n",
    "\n",
    "sampled['label'] = sampled['k_means_category'].apply(lambda x: cluster_names[x])\n",
    "\n",
    "# color by label name\n",
    "# setting up color map for plotting with standardized cluster colors across graphics\n",
    "categories = cluster_names.values()\n",
    "col = px.colors.qualitative.Plotly[:len(categories)]\n",
    "gray = '#BAB0AC'\n",
    "\n",
    "\n",
    "color_map_l = dict(zip(categories,  col))\n",
    "print(color_map_l)\n",
    "\n",
    "px_plot(sampled, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read preprocessed 10% sample of tweets generated by \"data_cleaning.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "sampled = pd.read_pickle(\"../data/010sample_091222.pkl\")\n",
    "# hover_text formats the tweets text with html formatting for line breaks \n",
    "sampled[\"hover_text\"] = sampled.full_text.apply(lambda txt: '<br>'.join(textwrap.wrap(txt, width=50)))\n",
    "sampled['size']=(sampled['retweet_count']+sampled['favorite_count']).apply(lambda x: np.log(x*x + 1))\n",
    "\n",
    "print(len(sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate high-dimensional vectors from your text for later reduction and plotting. This can take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "print(sampled)\n",
    "embeddings = get_embeddings(sampled['text_proc'], model_name=\"paraphrase-MiniLM-L6-v2\")\n",
    "# data = preprocessing.normalize(np.array(embeddings))\n",
    "\n",
    "# sampled['embeddings'] = pd.Series(embeddings)\n",
    "\n",
    "# data = np.array(embeddings)\n",
    "\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cell will run through all combinations of parameters: n_pca, n_neighbors, k-means value, and min_dist for PCA/UMAP reduction and k-means clustering, and produce a plot for each. This is helpful for testing the effects of different values and tweaking to find the best plot. Running too many in one cell can cause the plots to lag in the notebook, so it's also set up to save the plots for each parameter set so you can inspect them separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km_type = \"post\"\n",
    "\n",
    "# Set overwrite to True to always redo transformations. If False, will check for previously saved version of data\n",
    "overwrite = True\n",
    "\n",
    "for n_pca in [40]:\n",
    "    for n_neighbors in [500]:\n",
    "        for k in [7]:\n",
    "            for min_dist in [0.4]:\n",
    "                print(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "                \n",
    "                # Change this filepath to where you would like to save the plots:\n",
    "                tfm_fname = \"../models/mpox_tfm_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "\n",
    "                # check for saved version of transformed data; redo the transformation if it doesn't exist\n",
    "                if os.path.isfile(tfm_fname) and not overwrite:\n",
    "                    print(\"Previous file found\")\n",
    "                    tfm = pd.read_pickle(tfm_fname)\n",
    "                else:\n",
    "                    print(\"No file read - Computing new transformation:\")\n",
    "                    tfm = get_transform(data, method='both', n_pca=n_pca, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "                    \n",
    "                    k, score = sil_range(tfm, test_vals=np.arange(5,20))\n",
    "                    \n",
    "                    print(k, score)\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0).fit(tfm)\n",
    "                    tfm = pd.DataFrame(tfm)\n",
    "                    tfm['k_means_category'] = kmeans.labels_\n",
    "                    \n",
    "                    tfm_fname = \"../models/mpox_tfm_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "                    tfm.to_pickle(tfm_fname)\n",
    "\n",
    "                sampled['y'] = tfm[1]\n",
    "                sampled['x'] = tfm[0]\n",
    "                sampled['k_means_category'] = tfm['k_means_category']\n",
    "                \n",
    "                px_plot(sampled, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km_type = \"post\"\n",
    "overwrite=False\n",
    "\n",
    "for n_pca in [15]:\n",
    "    for n_neighbors in [30]:\n",
    "        for k in [25]:\n",
    "            for min_dist in [0.1]:\n",
    "                print(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "                \n",
    "                tfm_fname = \"../models/mpox_tfm_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "\n",
    "                # check for saved version of transformed data; create new if it doesn't exist\n",
    "                if os.path.isfile(tfm_fname) and not overwrite:\n",
    "                    print(\"Previous file found\")\n",
    "                    tfm = pd.read_pickle(tfm_fname)\n",
    "                else:\n",
    "                    print(\"No file read - Computing new transformation:\")\n",
    "                    tfm = get_transform(data, method='both', n_pca=n_pca, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "                    \n",
    "#                     k, score = sil_range(tfm, test_vals=np.arange(5,20))\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0).fit(tfm)\n",
    "                    tfm = pd.DataFrame(tfm)\n",
    "                    tfm['k_means_category'] = kmeans.labels_\n",
    "                    \n",
    "                    tfm_fname = \"../models/mpox_tfm_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist)\n",
    "                    tfm.to_pickle(tfm_fname)\n",
    "\n",
    "                sampled['y'] = tfm[1]\n",
    "                sampled['x'] = tfm[0]\n",
    "                sampled['k_means_category'] = tfm['k_means_category']\n",
    "                \n",
    "                px_plot(sampled, save=True, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More example runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca = 15\n",
    "n_neighbors = 30\n",
    "min_dist = 0.5\n",
    "\n",
    "kmtype = \"post\"\n",
    "\n",
    "print(n_pca, n_neighbors,  min_dist)\n",
    "\n",
    "print(\"Initial data shape:\", data.shape)\n",
    "\n",
    "# apply PCA\n",
    "fit = PCA(\n",
    "    n_components=n_pca\n",
    ")\n",
    "pca = fit.fit_transform(data)\n",
    "\n",
    "print(\"After PCA:\", pca.shape)\n",
    "\n",
    "sil_range(tfm, test_vals=np.arange(5,20))\n",
    "\n",
    "# apply Kmeans\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(tfm)\n",
    "\n",
    "# apply UMAP\n",
    "tfm = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=min_dist,\n",
    "    n_components=2,\n",
    "    metric='cosine'\n",
    ").fit_transform(pca)\n",
    "\n",
    "print(\"After UMAP:\", tfm.shape)\n",
    "\n",
    "sampled['y'] = tfm[:,1]\n",
    "sampled['x'] = tfm[:,0]\n",
    "\n",
    "sampled['k_means_category'] = kmeans.labels_\n",
    "\n",
    "\n",
    "px_plot(sampled, save=True, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_pca = 40\n",
    "n_neighbors = 30\n",
    "min_dist = 0.1\n",
    "\n",
    "print(n_pca, n_neighbors,  min_dist)\n",
    "\n",
    "print(\"Initial data shape:\", data.shape)\n",
    "\n",
    "# apply PCA\n",
    "fit = PCA(\n",
    "    n_components=n_pca\n",
    ")\n",
    "pca = fit.fit_transform(data)\n",
    "\n",
    "print(\"After PCA:\", pca.shape)\n",
    "\n",
    "k, score = sil_range(pca, test_vals=np.arange(5,20))\n",
    "\n",
    "\n",
    "# apply Kmeans (pre-UMAP)\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(pca)\n",
    "\n",
    "# apply UMAP\n",
    "tfm = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=min_dist,\n",
    "    n_components=2,\n",
    "    metric='cosine'\n",
    ").fit_transform(pca)\n",
    "\n",
    "print(\"After UMAP:\", tfm.shape)\n",
    "\n",
    "sampled['y'] = tfm[:,1]\n",
    "sampled['x'] = tfm[:,0]\n",
    "\n",
    "sampled['k_means_category'] = kmeans.labels_\n",
    "\n",
    "print(\"Pre-UMAP clustering:\")\n",
    "print(\"optimal k clusters:\", k, score)\n",
    "\n",
    "\n",
    "px_plot(sampled, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n",
    "\n",
    "\n",
    "k, score = sil_range(tfm, test_vals=np.arange(5,20))\n",
    "\n",
    "# apply Kmeans (post-UMAP)\n",
    "kmeans2 = KMeans(n_clusters=k, random_state=0).fit(tfm)\n",
    "\n",
    "sampled['k_means_category'] = kmeans2.labels_\n",
    "\n",
    "print(\"Post-UMAP clustering:\")\n",
    "print(\"optimal k clusters:\", k, score)\n",
    "\n",
    "\n",
    "px_plot(sampled, fname=\"../results/mpox_{}_{}_{}_{}_{}.html\".format(km_type, n_pca, n_neighbors, k, min_dist))\n",
    "\n",
    "# apply Kmeans (post-UMAP)\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(tfm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "54015868a28cda61386dc8f48c08f1981aeacb37f2b42a58b51bf6f8115a6f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
